package com.example.airis

import android.content.Context
import android.graphics.Bitmap
import org.tensorflow.lite.Interpreter
import java.io.FileInputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.MappedByteBuffer
import java.nio.channels.FileChannel

/**
 * TFLite EfficientNetB0 ëª¨ë¸ ë˜í¼
 * - ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ 1280ì°¨ì› ì„ë² ë”© ë²¡í„°ë¥¼ ì¶œë ¥
 * - Pythonì˜ preprocess_inputê³¼ ë™ì¼í•œ ì „ì²˜ë¦¬ ì ìš©
 */
class TFLiteModel(context: Context, modelFileName: String = "efficientnet_b0.tflite") {

    private var interpreter: Interpreter? = null

    // ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
    private val inputSize = 224
    private val pixelSize = 3 // RGB
    private val imageByteSize = inputSize * inputSize * pixelSize * 4 // Float32 = 4 bytes

    // ì¶œë ¥ ì„ë² ë”© í¬ê¸°
    private val embeddingSize = 1280

    init {
        try {
            println("ğŸ”§ TFLite ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘...")
            println("   ëª¨ë¸ íŒŒì¼: $modelFileName")

            // assetsì—ì„œ ëª¨ë¸ íŒŒì¼ ë¡œë“œ
            val modelBuffer = loadModelFile(context, modelFileName)
            println("   âœ“ ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì„±ê³µ (${modelBuffer.capacity()} bytes)")

            // Interpreter ì´ˆê¸°í™”
            val options = Interpreter.Options().apply {
                setNumThreads(4) // ë©€í‹°ìŠ¤ë ˆë“œ ì‚¬ìš©
            }
            interpreter = Interpreter(modelBuffer, options)
            println("   âœ“ Interpreter ì´ˆê¸°í™” ì„±ê³µ")

            println("âœ… TFLite ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: $modelFileName")

        } catch (e: Exception) {
            e.printStackTrace()
            println("âŒ TFLite ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: ${e.message}")
        }
    }

    /**
     * assets í´ë”ì—ì„œ ëª¨ë¸ íŒŒì¼ ë¡œë“œ
     */
    private fun loadModelFile(context: Context, modelFileName: String): MappedByteBuffer {
        val fileDescriptor = context.assets.openFd(modelFileName)
        val inputStream = FileInputStream(fileDescriptor.fileDescriptor)
        val fileChannel = inputStream.channel
        val startOffset = fileDescriptor.startOffset
        val declaredLength = fileDescriptor.declaredLength
        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)
    }

    /**
     * Bitmap ì´ë¯¸ì§€ì—ì„œ ì„ë² ë”© ì¶”ì¶œ
     * @param bitmap ì…ë ¥ ì´ë¯¸ì§€
     * @return 1280ì°¨ì› FloatArray (ì„ë² ë”© ë²¡í„°)
     */
    fun extractEmbedding(bitmap: Bitmap): FloatArray? {
        if (interpreter == null) {
            println("âŒ Interpreterê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return null
        }

        try {
            println("ğŸ“¸ ì„ë² ë”© ì¶”ì¶œ ì‹œì‘...")

            // 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            val inputBuffer = preprocessImage(bitmap)

            // 2. ì¶œë ¥ ë²„í¼ ì¤€ë¹„
            val outputBuffer = Array(1) { FloatArray(embeddingSize) }

            // 3. ì¶”ë¡  ì‹¤í–‰
            val startTime = System.currentTimeMillis()
            interpreter?.run(inputBuffer, outputBuffer)
            val endTime = System.currentTimeMillis()

            println("   âœ“ ì¶”ë¡  ì™„ë£Œ (${endTime - startTime}ms)")
            println("   âœ“ ì„ë² ë”© ì°¨ì›: ${outputBuffer[0].size}D")
            println("   âœ“ ì„ë² ë”© ìƒ˜í”Œ: [${outputBuffer[0].take(5).joinToString(", ") { "%.4f".format(it) }}...]")

            // 4. ê²°ê³¼ ë°˜í™˜
            return outputBuffer[0]

        } catch (e: Exception) {
            e.printStackTrace()
            println("âŒ ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨: ${e.message}")
            return null
        }
    }

    /**
     * ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (EfficientNet preprocess_input ë°©ì‹)
     *
     * Python ì½”ë“œì™€ ë™ì¼:
     * ```python
     * from tensorflow.keras.applications.efficientnet import preprocess_input
     * img = preprocess_input(img)  # [0,255] â†’ [-1,1]
     * ```
     *
     * ë³€í™˜ ê³µì‹: (pixel / 127.5) - 1.0
     * - [0, 255] â†’ [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”
     */
    private fun preprocessImage(bitmap: Bitmap): ByteBuffer {
        // 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        val resizedBitmap = Bitmap.createScaledBitmap(bitmap, inputSize, inputSize, true)

        // ByteBuffer ìƒì„±
        val inputBuffer = ByteBuffer.allocateDirect(imageByteSize).apply {
            order(ByteOrder.nativeOrder())
        }

        // í”½ì…€ ê°’ì„ ë²„í¼ì— ì¶”ê°€
        val intValues = IntArray(inputSize * inputSize)
        resizedBitmap.getPixels(intValues, 0, resizedBitmap.width, 0, 0, resizedBitmap.width, resizedBitmap.height)

        var pixel = 0
        for (i in 0 until inputSize) {
            for (j in 0 until inputSize) {
                val value = intValues[pixel++]

                // RGB ê°’ ì¶”ì¶œ
                val r = ((value shr 16) and 0xFF).toFloat()
                val g = ((value shr 8) and 0xFF).toFloat()
                val b = (value and 0xFF).toFloat()

                // âœ… EfficientNet preprocess_input ì ìš©
                // [0, 255] â†’ [-1, 1]
                val normalizedR = (r / 127.5f) - 1.0f
                val normalizedG = (g / 127.5f) - 1.0f
                val normalizedB = (b / 127.5f) - 1.0f

                inputBuffer.putFloat(normalizedR)
                inputBuffer.putFloat(normalizedG)
                inputBuffer.putFloat(normalizedB)

                // ë””ë²„ê¹…: ì²« í”½ì…€ë§Œ ì¶œë ¥
                if (pixel == 1) {
                    println("   ğŸ¨ ì²« í”½ì…€ ì „ì²˜ë¦¬:")
                    println("      ì›ë³¸ RGB: [$r, $g, $b]")
                    println("      ì •ê·œí™” í›„: [%.4f, %.4f, %.4f]".format(normalizedR, normalizedG, normalizedB))
                }
            }
        }

        return inputBuffer
    }

    /**
     * ë¦¬ì†ŒìŠ¤ í•´ì œ
     */
    fun close() {
        interpreter?.close()
        interpreter = null
        println("âœ… TFLite ëª¨ë¸ ë¦¬ì†ŒìŠ¤ í•´ì œ")
    }
}