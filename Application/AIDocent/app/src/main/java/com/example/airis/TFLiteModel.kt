package com.example.airis

import android.content.Context
import android.graphics.Bitmap
import android.graphics.Canvas
import android.graphics.Color
import android.graphics.Paint
import org.tensorflow.lite.Interpreter
import java.io.FileInputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.MappedByteBuffer
import java.nio.channels.FileChannel
import kotlin.math.min

/**
 * CLIP ëª¨ë¸ìš© TFLite ë˜í¼
 * - ëª¨ë¸ëª…: art_clip_model.tflite
 * - ì „ì²˜ë¦¬: (Pixel - Mean) / Std
 */
class TFLiteModel(
    context: Context,
    // ğŸ”¥ [ìˆ˜ì •] ê¸°ë³¸ ëª¨ë¸ëª…ì„ CLIP ëª¨ë¸ë¡œ ë³€ê²½
    modelFileName: String = "art_clip_model.tflite"
) {

    private var interpreter: Interpreter? = null
    private val inputSize = 224
    private val imageByteSize = inputSize * inputSize * 3 * 4
    private val embeddingSize = 128

    init {
        try {
            val modelBuffer = loadModelFile(context, modelFileName)
            val options = Interpreter.Options().apply { setNumThreads(4) }
            interpreter = Interpreter(modelBuffer, options)
            println("âœ… CLIP ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: $modelFileName")
        } catch (e: Exception) {
            e.printStackTrace()
            println("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: ${e.message}")
        }
    }

    private fun loadModelFile(context: Context, modelFileName: String): MappedByteBuffer {
        val fileDescriptor = context.assets.openFd(modelFileName)
        val inputStream = FileInputStream(fileDescriptor.fileDescriptor)
        val fileChannel = inputStream.channel
        return fileChannel.map(FileChannel.MapMode.READ_ONLY, fileDescriptor.startOffset, fileDescriptor.declaredLength)
    }

    fun extractEmbedding(bitmap: Bitmap): FloatArray? {
        if (interpreter == null) return null
        try {
            val inputBuffer = preprocessImage(bitmap)
            val outputBuffer = Array(1) { FloatArray(embeddingSize) }
            interpreter?.run(inputBuffer, outputBuffer)
            return outputBuffer[0]
        } catch (e: Exception) {
            e.printStackTrace()
            return null
        }
    }

    /**
     * ğŸ”¥ [í•µì‹¬] CLIP ì „ìš© ì „ì²˜ë¦¬ (Letterbox + Mean/Std ì •ê·œí™”)
     */
    private fun preprocessImage(bitmap: Bitmap): ByteBuffer {
        // 1. Letterbox Resizing
        val targetW = inputSize
        val targetH = inputSize
        val scale = min(targetW.toFloat() / bitmap.width, targetH.toFloat() / bitmap.height)
        val scaledW = (bitmap.width * scale).toInt()
        val scaledH = (bitmap.height * scale).toInt()

        val scaledBitmap = Bitmap.createScaledBitmap(bitmap, scaledW, scaledH, true)
        val bgBitmap = Bitmap.createBitmap(targetW, targetH, Bitmap.Config.ARGB_8888)
        val canvas = Canvas(bgBitmap)
        canvas.drawColor(Color.BLACK)
        canvas.drawBitmap(scaledBitmap, (targetW - scaledW) / 2f, (targetH - scaledH) / 2f, Paint(Paint.FILTER_BITMAP_FLAG))

        // 2. Normalization (CLIP Mean/Std ì ìš©)
        val inputBuffer = ByteBuffer.allocateDirect(imageByteSize)
        inputBuffer.order(ByteOrder.nativeOrder())
        val intValues = IntArray(inputSize * inputSize)
        bgBitmap.getPixels(intValues, 0, inputSize, 0, 0, inputSize, inputSize)

        // CLIP ê³µì‹ ìƒìˆ˜ (RGB ìˆœì„œ)
        val mean = floatArrayOf(0.48145466f, 0.4578275f, 0.40821073f)
        val std = floatArrayOf(0.26862954f, 0.26130258f, 0.27577711f)

        for (pixel in intValues) {
            val r = ((pixel shr 16) and 0xFF) / 255.0f
            val g = ((pixel shr 8) and 0xFF) / 255.0f
            val b = (pixel and 0xFF) / 255.0f

            // ğŸ”¥ (ê°’ - í‰ê· ) / í‘œì¤€í¸ì°¨
            inputBuffer.putFloat((r - mean[0]) / std[0])
            inputBuffer.putFloat((g - mean[1]) / std[1])
            inputBuffer.putFloat((b - mean[2]) / std[2])
        }
        return inputBuffer
    }

    fun close() {
        interpreter?.close()
        interpreter = null
    }
}